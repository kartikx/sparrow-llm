"""
- What layers do I need.
- How do I tokenizer it?
- How do i invoke it with a request?
"""

"""
Layers

- input layer-norm

- attention block
    - q, k, v
    - self-attention
    - output projection

layer-norm

residual
    
- mlp
    - up proj
    - down proj

residual?
"""